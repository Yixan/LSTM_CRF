{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cws.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_QpdOyeEy73o","colab_type":"code","outputId":"d2365aea-248e-4a25-88d2-e0eb4c2ff7fb","executionInfo":{"status":"ok","timestamp":1559314105111,"user_tz":-480,"elapsed":279261,"user":{"displayName":"张艺璇","photoUrl":"","userId":"13417831249388151815"}},"colab":{"base_uri":"https://localhost:8080/","height":178}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive  -o nonempty\n","!pip install -q keras\n","\n","%cd /content/drive/colab\n","%ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n","[Errno 2] No such file or directory: '/content/drive/colab'\n","/content\n","adc.json  \u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mmyproject\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GU3hC7No0x-D","colab_type":"code","colab":{}},"source":["!mkdir -p myproject\n","!google-drive-ocamlfuse myproject"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYONlvXu0Uz-","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"myproject/NLP\") \n","import tensorflow as tf\n","from tensorflow.contrib.crf import viterbi_decode\n","import lstm_crf_data_helper, lstm_crf_model\n","import fileUtil\n","import pandas\n","from pandas import DataFrame\n","'''定义常量'''\n","MODEL_SAVE_PATH='model5-31-cws/'\n","MODEL_NAME='checkpoint5-31'\n","csv_name='400-32-0.5-0.8.csv'\n","tf.app.flags.DEFINE_string(\"f\",\"\",\"test\")\n","tf.flags.DEFINE_integer(\"embeddings_size\", 400, \"每个字向量的维度\")\n","tf.flags.DEFINE_integer(\"hidden_dim\", 400, \"LSTM隐藏层细胞的个数\")\n","tf.flags.DEFINE_integer(\"batch_size\", 32, \"每个批次的大小\")\n","tf.flags.DEFINE_integer(\"num_epochs\", 2, \"训练的轮数\")\n","tf.flags.DEFINE_float(\"keep_prob\", 0.5, \"丢失率\")\n","tf.flags.DEFINE_float(\"forget_bias\", 0.8, \"遗忘率\")\n","tf.flags.DEFINE_float(\"clip_grad\", 5.0, \"梯度的范围\")\n","tf.flags.DEFINE_float(\"learning_rate\", 0.001, \"学习率\")\n","tf.app.flags.DEFINE_string(\"train_dir\",\"log\",'储存路径')\n","FLAGS = tf.flags.FLAGS"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_a3rT9Tx4dXF","colab_type":"code","outputId":"1863798b-5edb-4978-cfb5-72ebd5782222","executionInfo":{"status":"ok","timestamp":1559315394660,"user_tz":-480,"elapsed":3457,"user":{"displayName":"张艺璇","photoUrl":"","userId":"13417831249388151815"}},"colab":{"base_uri":"https://localhost:8080/","height":193}},"source":["tag2label = {'0':0,'B':1,'M':2,'E':3,'S':4}\n","label2tag = {0:'0',1:'B',2:'M',3:'E',4:'S'}\n","x = tf.placeholder(tf.int32, [None, None], name='input')\n","y = tf.placeholder(tf.int32, [None, None], name='output')\n","#每一句的长度\n","sequence_lengths = tf.placeholder(tf.int32, shape=[None], name=\"sequence_lengths\")\n","#丢失率\n","keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n","# 获得字与字索引映射的向量\n","word2id_dict = lstm_crf_data_helper.get_word_id('data/char2num.pkl')\n","# word2id_dict = lstm_crf_data_helper.get_word_id('data\\\\char2num.pkl')\n","# 获得总的标注类别数\n","num_tags = len(tag2label)\n","'''处理数据'''\n","def get_data(file_location):\n","    # 获得数据\n","    # sentences_list, tags_list是没有按照最大长度填充的标签\n","    sentences_list, tags_list = fileUtil.get_data(file_location)\n","    sentences_list\n","    print('------------------------------------------------------------------')\n","#     tags_list\n","    # 完成tag向索引的映射\n","    tags_id_list = lstm_crf_data_helper.tags2id(tags_list, tag2label)\n","    # 对索引进行填充\n","    labels, _ = lstm_crf_data_helper.padding_sentences(tags_id_list)\n","    # 获得句子中每个字的id\n","    sentences_id_list = lstm_crf_data_helper.sentence2idcws(sentences_list, word2id_dict)\n","    # 对句子或标注序列索引进行填充并获得每个句子的长度\n","    sen_index_list, sen_len_list = lstm_crf_data_helper.padding_sentences(sentences_id_list)\n","    return sen_index_list, labels, sen_len_list, tags_list\n","\n","'''得到参考的标签'''\n","def get_refer_tag(referfile):\n","    refer_list=[]\n","    with open(referfile,'r',encoding = 'UTF-8') as f:\n","        lines=f.readlines()\n","        for line in lines:\n","            line=line.strip()\n","            words = line.split()\n","            refer_list.append(words)\n","    return refer_list\n","\n","'''标签转化成词语'''\n","def label2word(label_list,model):\n","    if model=='test':\n","        refer_file='data/test.txt'\n","    else:\n","        refer_file='data/val.txt'\n","    tags_list = []\n","    for labels in label_list:\n","        tags = []\n","        for i in labels:\n","            tags.append(label2tag[i])\n","        tags_list.append(tags)\n","    refer_list=[]\n","    with open(refer_file,'r',encoding='utf-8') as file:\n","        lines=file.readlines()\n","        for line in lines:\n","            words=line.split()\n","            for word in words:\n","#                 print(word.split(\"##\")[0])\n","                refer_list.append(word.split(\"##\")[0])\n","    i=0\n","    word=''\n","    sentences_list=[]\n","    for tags in tags_list:\n","        sentences=''\n","        for tag in tags:\n","            if tag=='S':\n","                sentences=sentences+' '+refer_list[i]+' '\n","            elif tag=='B':\n","                sentences=sentences+' '+refer_list[i]\n","            elif tag=='M':\n","                sentences=sentences+refer_list[i]\n","            elif tag=='E':\n","                sentences=sentences+refer_list[i]+' '\n","            i=i+1\n","        sen=sentences.split()\n","        sentences_list.append(sen)\n","    return sentences_list\n","\n","test_words_list=get_refer_tag('data/test_cws1.txt')\n","val_words_list=get_refer_tag('data/val_cws.txt')\n","train_sen_index_list, train_labels, train_sen_len_list, _ = get_data('data/train.txt')\n","val_sen_index_list, val_labels, val_sen_len_list, val_tags_list=get_data('data/val.txt')\n","test_sen_index_list, test_labels, test_sen_len_list, test_tags_list = get_data('data/test.txt')\n","\n","'''计算F'''\n","def evalute(sentences_list,refer_list):\n","    print(sentences_list[0])\n","    count_right = 0\n","    count_split = 0\n","    count_gold = 0\n","    for i,sentence in enumerate(sentences_list):\n","        # sentence = sentence.strip()\n","        # goldlist = sentence.split()\n","        count_gold += len(sentence)\n","        tmp_gold = sentence\n","        line2 =refer_list[i]\n","        # line2 = line2.strip()\n","        inlist = line2\n","        count_split += len(inlist)\n","        tmp_in = inlist\n","        for key in tmp_in:\n","            if key in tmp_gold:\n","                count_right += 1\n","                tmp_gold.remove(key)\n","\n","    P = count_right / count_split\n","    R = count_right / count_gold\n","    return  2 * P * R / (P + R)\n","\n","'''解码得到句子'''\n","def decode(logits, transition_params,model):\n","    if model=='test':\n","        words_list=test_words_list\n","        sen_len_list=test_sen_len_list\n","    else:\n","        words_list=val_words_list\n","        sen_len_list=val_sen_len_list\n","    # 对测试集进行测试\n","    label_list = []\n","    sentences_list=[]\n","    for logit, seq_len in zip(logits, sen_len_list):\n","        # viterbi_decode通俗一点,作用就是返回最好的标签序列.这个函数只能够在测试时使用,在tensorflow外部解码\n","        # viterbi: 一个形状为[seq_len] 显示了最高分的标签索引的列表.\n","        # viterbi_score: 序列对应的概率值\n","        # 这是解码的过程，利用维比特算法结合概率转移矩阵求得最大的可能标注概率\n","        viterbi_seq, _ = viterbi_decode(logit[:seq_len], transition_params)\n","        label_list.append(viterbi_seq)\n","    sentences_list = label2word(label_list,model)\n","    # F = evalute(sentences_list, words_list)\n","    return sentences_list,words_list\n","\n","'''生成CSV'''\n","def write2CSV(para_dict):\n","    df = DataFrame(para_dict)\n","    df.to_csv(csv_name,index=False,sep=',')\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["final get_word_id\n","------------------------------------------------------------------\n","final tags2id\n","final sentence2id\n","------------------------------------------------------------------\n","final tags2id\n","final sentence2id\n","------------------------------------------------------------------\n","final tags2id\n","final sentence2id\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rKlsSvlcA6y0","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"Uhhd6UQDA8Pw","colab_type":"code","colab":{}},"source":["get_data('data/val.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xYLsvcBh5JW1","colab_type":"code","outputId":"e6428dca-23af-482b-e638-c1604c397153","executionInfo":{"status":"error","timestamp":1559315400453,"user_tz":-480,"elapsed":2447,"user":{"displayName":"张艺璇","photoUrl":"","userId":"13417831249388151815"}},"colab":{"base_uri":"https://localhost:8080/","height":582}},"source":["losslist=[]\n","# 首先是embedding层获得词向量数据\n","with tf.name_scope(\"embedding\"):\n","    #构造词嵌入矩阵，每个词向量维度为300维，随机产生\n","    embedding_mat = lstm_crf_data_helper.random_embedding(word2id_dict, FLAGS.embeddings_size)\n","    print(len(embedding_mat))\n","    #选取此嵌入矩阵里索引对应的元素\n","    input_x = tf.nn.embedding_lookup(embedding_mat, x)\n","    # input_x=tf.nn.dropout(input_x,keep_prob=FLAGS.keep_prob)\n","#构建神经网络\n","BiLSTM_CRF = lstm_crf_model.BiLSTM_CRF(FLAGS.hidden_dim, num_tags, input_x, sequence_lengths, keep_prob, y,FLAGS.forget_bias)\n","#前向传播，loss:损失函数值,transition_params是:RF的转换矩阵,logits是预测值\n","loss, transition_params, logits = BiLSTM_CRF.positive_propagation()\n","#全局步数\n","global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n","#自适应学习率\n","# learning_rate=tf.train.exponential_decay(3.0, global_step, 3, 0.3, staircase=True)\n","#优化器\n","optim = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)\n","# optim = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","# 计算梯度，返回的是：A list of (gradient, variable) pairs\n","grads_and_vars = optim.compute_gradients(loss)\n","#控制梯度范围，还不知道g,v的具体含义\n","grads_and_vars_clip = [[tf.clip_by_value(g, -FLAGS.clip_grad, FLAGS.clip_grad), v] for g, v in grads_and_vars]\n","#将计算出的梯度应用到变量上，是函数minimize()的第二部分，返回一个应用指定的梯度的操作Operation，对global_step做自增操作\n","train_op = optim.apply_gradients(grads_and_vars_clip, global_step=global_step)\n","#断点续训\n","saver = tf.train.Saver()\n","# tensorboard可视化\n","for var in tf.trainable_variables():\n","    tf.summary.histogram(var.name, var)\n","merged_summary_op = tf.summary.merge_all()\n","losslist = []\n","test_f_list = []\n","val_f_list = []\n","g_list=[]\n","v_list=[]\n","lr_list=[]\n","with tf.Session() as sess:\n","    tf.initialize_all_variables().run()\n","    writer = tf.summary.FileWriter(FLAGS.train_dir, sess.graph)\n","    # 模型的训练\n","    num_inter = int(len(train_sen_len_list) / FLAGS.batch_size)\n","    # 训练epoch轮\n","    step = 0\n","    j=0\n","    ckpt = tf.train.get_checkpoint_state(MODEL_SAVE_PATH)  # 获取checkpoints对象\n","    if ckpt and ckpt.model_checkpoint_path:  ##判断ckpt是否为空，若不为空，才进行模型的加载，否则从头开始训练\n","        saver.restore(sess, ckpt.model_checkpoint_path)  # 恢复保存的神经网络结构，实现断点续训\n","    for epoch in range(FLAGS.num_epochs):\n","        # 每一轮中分batch训练\n","        for i in range(num_inter):\n","            start = i * FLAGS.batch_size\n","            end = (i + 1) * FLAGS.batch_size\n","            feed_dict = {x: train_sen_index_list[start:end], y: train_labels[start:end],\n","                         sequence_lengths: train_sen_len_list[start:end], keep_prob: FLAGS.keep_prob}\n","            # gv = sess.run(grads_and_vars_clip)\n","#             train_loss= sess.run(loss,feed_dict=feed_dict)\n","            if i % 10 == 0:\n","            # 算loss\n","              train_loss = sess.run(loss,\n","                                    feed_dict={x: train_sen_index_list[start:end], y: train_labels[start:end],\n","                                               sequence_lengths: train_sen_len_list[start:end],\n","                                               keep_prob: FLAGS.keep_prob})\n","              losslist.append(train_loss)\n","              # 验证集准确率\n","              logits2, transition_params2  = sess.run([logits, transition_params], feed_dict={\n","                  x: val_sen_index_list, y: val_labels,\n","                  sequence_lengths: val_sen_len_list, keep_prob: 1.0\n","              })\n","              sentences_list, words_list = decode(logits2, transition_params2, model='val')\n","              F1 = evalute(sentences_list, words_list)\n","              val_f_list.append(F1)\n","              print(\"验证集F的值为{:.4f}：\" .format(F1))\n","              # 测试集准确率\n","              logits1, transition_params1 = sess.run([logits, transition_params], feed_dict={\n","                  x: test_sen_index_list, y: test_labels,\n","                  sequence_lengths: test_sen_len_list, keep_prob: 1.0\n","              })\n","              sentences_list, words_list = decode(logits1, transition_params1,model='test')\n","              F = evalute(sentences_list, words_list)\n","              test_f_list.append(F)\n","              print(\"测试集F的值为{:.4f}：\" .format(F))\n","\n","              merged_summary = tf.summary.merge_all()\n","              summary = sess.run(merged_summary_op,\n","                                 feed_dict={x: train_sen_index_list[start:end], y: train_labels[start:end],\n","                                            sequence_lengths: train_sen_len_list[start:end],\n","                                            keep_prob: FLAGS.keep_prob})\n","              writer.add_summary(summary, step)\n","              step = step + 1\n","              print(\"总步数:\", step)\n","              print(\"epoch:%d step:%d loss is:%s\" % (epoch + 1, i, train_loss))\n","            # 更新变量不算loss\n","            sess.run(train_op, feed_dict=feed_dict)\n","        if val_f_list[-1]<val_f_list[-2]:\n","            print(\"提前终止，轮数%d\"%(epoch+1))\n","        saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n","        writer.close()\n","\n","para_dict={'loss':losslist,'val_f':val_f_list,'test_f':test_f_list}\n","write2CSV(para_dict)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2850\n","final random_embedding\n","2851\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-2d2e2cc89d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mBiLSTM_CRF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_crf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBiLSTM_CRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforget_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#前向传播，loss:损失函数值,transition_params是:RF的转换矩阵,logits是预测值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBiLSTM_CRF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#全局步数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"global_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/myproject/NLP/lstm_crf_model.py\u001b[0m in \u001b[0;36mpositive_propagation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# output_fw_seq和output_bw_seq的shape都是[batch_size, sequence_length, num_units]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             (output_fw_seq, output_bw_seq), _ = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, self.input_x,\n\u001b[0;32m---> 27\u001b[0;31m                                                                                 self.sequence_lengths, dtype=tf.float32)\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mout_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_fw_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_bw_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 对正反向的输出进行合并\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mout_put\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_put\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_pl\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 防止过拟合\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mbidirectional_dynamic_rnn\u001b[0;34m(cell_fw, cell_bw, inputs, sequence_length, initial_state_fw, initial_state_bw, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    441\u001b[0m           \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state_fw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m           time_major=time_major, scope=fw_scope)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;31m# Backward direction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3554\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3555\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3556\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3557\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3558\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3085\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3086\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3087\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3088\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   3020\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m   3021\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3523\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3524\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    843\u001b[0m           \u001b[0mcall_cell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcall_cell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m           \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m           skip_conditionals=True)\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_rnn_step\u001b[0;34m(time, sequence_length, min_sequence_length, max_sequence_length, zero_output, state, call_cell, state_size, skip_conditionals)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# steps.  This is faster when max_seq_len is equal to the number of unrolls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;31m# (which is typical for dynamic_rnn).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mnew_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\n\u001b[0;32m--> 371\u001b[0;31m                                      *args, **kwargs)\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m     \u001b[0;31m# Only call `build` if the user has manually overridden the build method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    149\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         partitioner=maybe_partitioner)\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1230\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m     \u001b[0;34m\"\"\"Alias for `add_weight`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             getter=vs.get_variable)\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    350\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    605\u001b[0m     new_variable = getter(\n\u001b[1;32m    606\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1477\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1218\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    545\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    497\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" % (err_msg, \"\".join(\n\u001b[0;32m--> 848\u001b[0;31m             traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Variable lstm-crf/bidirectional_rnn/fw/lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/content/myproject/NLP/lstm_crf_model.py\", line 27, in positive_propagation\n    self.sequence_lengths, dtype=tf.float32)\n  File \"<ipython-input-3-2d2e2cc89d8a>\", line 13, in <module>\n    loss, transition_params, logits = BiLSTM_CRF.positive_propagation()\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"]}]},{"cell_type":"code","metadata":{"id":"nt_bTkjW4c-n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":239},"outputId":"fd02655e-ce25-4f8a-c762-4750106a47bd","executionInfo":{"status":"error","timestamp":1559315191365,"user_tz":-480,"elapsed":3582,"user":{"displayName":"张艺璇","photoUrl":"","userId":"13417831249388151815"}}},"source":["word_list=[]\n","with open (\"test2.txt\",'r',encoding='utf-8') as f:\n","  lines=f.readlines()\n","  words=[]\n","  for word in lines:\n","      words.append(word)\n","  word_list.append(words)\n","  words=[]\n","    \n","    \n","with open (\"label.txt\",'w',encoding='utf-8') as file:\n","  for sentence,words in zip(sentences_list,word_list):\n","    for label,word in zip(sentence,words):\n","      tag=label2tag[label]\n","      if tag=='S':\n","        filef.write(' '+word+' ')\n","      elif tag=='B':\n","        file.write(' ' + word)\n","      elif tag== 'M':\n","         file.write(word)\n","      elif tag == 'E':\n","         file.write(word+' ')\n","      file.write('\\n')\n","    "],"execution_count":7,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-2152a1b37a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfilef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '近2'"]}]},{"cell_type":"code","metadata":{"id":"EWr4esT9dQ5K","colab_type":"code","colab":{}},"source":["def get_data(file_location):\n","    # 获得数据\n","    # sentences_list, tags_list是没有按照最大长度填充的标签\n","    sentences_list, tags_list = fileUtil.get_data(file_location)\n","    sentences_list\n","    print('------------------------------------------------------------------')\n","#     tags_list\n","    # 完成tag向索引的映射\n","    tags_id_list = lstm_crf_data_helper.tags2id(tags_list, tag2label)\n","    # 对索引进行填充\n","    labels, _ = lstm_crf_data_helper.padding_sentences(tags_id_list)\n","    # 获得句子中每个字的id\n","    sentences_id_list = lstm_crf_data_helper.sentence2idcws(sentences_list, word2id_dict)\n","    # 对句子或标注序列索引进行填充并获得每个句子的长度\n","    sen_index_list, sen_len_list = lstm_crf_data_helper.padding_sentences(sentences_id_list)\n","    return sen_index_list, labels, sen_len_list, tags_list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zR9BRevxblVP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"2fb8ae8c-d08f-465a-b531-e968ce34a61b","executionInfo":{"status":"ok","timestamp":1559315250769,"user_tz":-480,"elapsed":1169,"user":{"displayName":"张艺璇","photoUrl":"","userId":"13417831249388151815"}}},"source":["print(sentences_list)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[['近2', '有过', '10', '<sup>9<>', '内用', '血清', '白蛋白', '2g', '1', '应', '该', '硫唑', '嘌呤', '1'], [], ['多于', '生后', '视其', '而定', '吸气', '时', '气管', '镜下'], ['沙门菌', '病情', '严重', '情况', '不明', '头孢霉素', '头孢噻肟', '等', '敏感株'], ['柯萨', '奇', '肌肉蛋白', '可', '能', 'HLA-B8', 'DR3'], ['+UA', 'UA-UC=', 'Na<sup>+<>', 'Cl<sup>-<>'], [], [], ['造血系统'], [], ['其', '中', '以生', '五', '日风', 'θ波', '现', '在'], ['第3版'], ['颅内占位性'], ['受遗传', '一', '级'], ['可及', '滚', '动样'], ['减退症', '比', '较'], ['c', 'm长', '分叉', '同于', '右主', '左主', '右支气管', '软化征', '平滑', '肌少', '小', '比', '相对', '比', '无', '效腔', '较', '0.4', '0.5', '0.3', '插管', '细支', '气管', '气道', '或', '者', '气道'], ['用', '作', '呼吸脉', '冲信号', '发出', '报警', '能感', '受到', '肩胸部', '过弱', '监护', '仪可', '能测', '上数', '层布', '超低体', '重儿'], ['相打开', '相压力', '供气做'], ['羊水', '细胞', '13', '-', '三体', '综合征', '或', '者', '类', '同外', '周血', '淋巴细胞'], ['刘丽', '卢惠珍', '非典型', '肺炎', '诊治体会'], ['阻塞学', '说'], ['三', '大', '及', '其'], ['减少性'], ['多', '尿期', '尿', '量渐', '血BUN', '亦逐步', '肾', '功能', '肾', '功能'], [], ['先有', '肋间', '隙及', '肋弓', '铁锈', '色痰', '脑病'], ['脑', '积水', '很', '多', '中', '脑导水管', '交通性'], ['较', '为', '2', '4', '过敏', '反应'], ['肾小管酸', '维生素D', 'Wilson病', '幼年类', '风湿', '各原', '发病', '中以', '较', '为'], ['不稳', '以α', '以7'], [], [], ['纵', '向', '着', '重于', '拒绝上学'], ['分泌儿', '茶酚胺激素', '盐皮质激素', '束状带', '间层', '75%', '糖皮质激素', '脱氧皮质醇', '皮质酮', '网状带', '位于', '肾上腺雄激素', '肾上腺皮质激素', '酶促', '诸多类', '固醇', '中', '羟类固醇', '蛋白超', '家族', '类固醇激素'], [], ['可见', '到', '胰腺坏', '死区', '低', '密度', '透亮区', '值', '得', '不', '能'], ['条件', '脱敏', '疗法', '无', '换用', '头孢', '曲松'], ['此', '外', '后', '代时', '则', '后', '代时', '则', '尚', '可', 'n结', '构发', '生缩减', '所携', '有', '1条FMR-1', 'X', '染色体', '全突', '变型', 'FMR-1基因', '全突', '变型', 'FMR-1基因', '变化', '趋势', '还', '是', '变化', 'FMR-1'], ['肾上腺', '皮质', '激素'], ['绝大', '部分', '嵌合', '体型', '大则', '较', '其行', '为', '抽象', '思维'], ['1', '3', '性别', '差异', '明确SARS', '接触史'], ['绕颈', '剖宫', '产', '绕颈', '脐动脉', '不', '易', '胎', '盘间', '失血量', '血容量', '剖宫', '产结', '扎脐', '带', '静力压', '血经', '脐静脉', '脐动脉', '血容量', '早剥', '极', '易', '及剖', '宫产'], ['结核菌血症'], ['许积', '德', '内科学', '人民', '卫生', '出版社'], [], ['该', '病为', '初为', '睑', '内翻', '擦伤角膜'], ['上', '臂围', '上', '臂围', '了', '解该', '左上肢放松', '测', '处系', '肱', '骨成', '勿压', '迫', '皮下', '组织'], [], ['可', '意料', '者', '苯等', '止痛', '药', '抗癫', '痫药'], ['新毒株', '取发', '病5', '鼻咽'], ['每', '连服', '天', '治愈者', '可于', '服泻药', '虽低'], ['ICD', '-', '10'], [], [], ['多', '次'], ['指易', '应', '该'], ['胃', '肠道', '转移瘤', '增多症', '嗜红细胞', '骨髓细菌'], [], [], [], ['由蛲虫寄', '生于', '会', '阴及'], ['巨大神经节', '巨大神经节', '所见', '60%', '树芽状', '串珠样', '不累', '及', '固有', '层常', '神经细胞', '其', '中', '30%', '55%', '下', '层', '巨大神经节', '至', '少要', '统', '一', '给IND', '神经节细胞', '减少症', '丛', '相', '伴发', '肠', '梗阻'], ['多', '数', '不', '安', '好哭', '头皮痒', '枕头上摇头'], ['盘状红斑'], ['峰', '影响环', 'TF', 'V环', '下', '降支', '封底彩图', '1b', '越重', '支斜率', '向', '内', '流速', '环呈', '1c', '之故'], ['敏感细胞', '多核巨细胞', '先做', '豚', '鼠', '再作', '培养物', '免疫荧光法'], [], [], ['已知'], ['2003年', '2', '3', '调查', '报告', '11%', '37nmol', '维生素D', '62nmol', '维生素D', '30%', '维生素D', '2006年', '爱阿', '华州', '维生素D', '结果', '显示', '3', '4', 'D补', '充剂', '8名', '23%', '血25', '27nmol'], [], ['抗', 'HBsAg', '这', '也', '是'], [], [], ['因其', '之', '中', '可', '不', '地把', '“缩', '微版', '三原', '则', '”指', '三种', '三种', '新开', '具', '时要'], ['世界', '大战', '此称', '为', '那时起', '应', '激物', 'posttraumatic'], ['所', '能', '呼气量', '细支', '气管', '呼气相', '呼气量'], ['病后', '正常', '亦于', '恢复'], ['颈面型', '放线菌病', '胸部型', '放线菌病', '腹部型', '放线菌病', '皮肤型', '放线菌病', '脑型', '放线菌病', '放线菌病'], ['C反应', '冷', '凝集', '周者', '加做', '抗溶血素', '链球菌', '“O', '类风湿因子'], ['精氨酸琥', '珀酸'], [], ['弥散系数', '气压', '分别', '2', '1.4', '5', '15', '为', '弥散量', '比氧', '大', '肺', '损伤'], [], ['严重', '者', '多', '次'], [], ['两侧', '肺野透', '亮度', '白肺', '几天'], [], ['出版必', '将', '儿科学', '界', '从', '事儿', '科专业', '都', '会', '从', '中'], ['是', '以', '其实', '不然', '约7%', '有OSAS者'], [], [], ['运动', '神经', '元位', '于', '颈3', '支配膈肌', '胸段', '中', '继站'], ['对症'], ['会', '阴', '横纹', '肌肉瘤', '极差', '横纹', '肌肉瘤', '非', '常大', '5人', '行胰', '十二指肠', '切除术'], ['弹足', '底', '粗暴拍打', '吸', '呼比', 'cmH<sub>2<>O', '呼吸音', '30', '秒后'], [], [], [], ['疫情', '报告', '接触史', '应予', '以'], ['病因繁', '多倾', '向于', '非甾体类'], [], ['中钙', '磷含量', '人乳', '中钙', '磷含量', '虽低', '磷含量', '钙磷比例', '不', '当'], ['后', '下部', '口', '右', '移位', '6例', '冠状窦'], ['低密度', '分', '布于', '低密度', '白质', '对', '比', '弥漫性', '低密度', '白质', '变窄', 'HIE低', 'CT值'], ['多种', '多样', '种', '类繁', '多', '有', '赖于', '一', '一'], [], [], ['最大'], ['铁', '丝圈样', '内', '皮下', '致', '密物', '新月体', '肾小血管', '⑦间质', '单核细胞', '者', '皮质激素', '新月体', '肾间质', '肾小囊', '肾小血管', '慢性', '化', '就Ⅳ型', '病变'], ['除极', '少数', '基本', '上'], [], ['检查', '台', '手托', '双上肢', '双腿', '双上', '肢收', '回', '拥抱动作'], ['一', '旦疑', '诊', '肾损害', '停药'], ['Rh血型', 'Rh血型', 'ABO', 'ABO', '宜用', '不'], ['摄', '水量', '至', '少'], [], [], ['东南', '大学'], [], ['数学学习'], [], [], ['多', '种'], ['天', '每4', '紫', '外线', '不', '少于', '1小时', '效氯', '每', '天', '有'], ['流行病学', '史'], [], [], ['组织细胞'], ['S比值', '可达', '不能', '磷脂酰', '甘油', 'SP-A', '肺成熟', '偏低', '如', '果L', 'SP-A', '显微', '镜', '微泡', '计数法', '表面', '物质', '活性', '有助', '于', '床旁'], ['差则', '2.66kPa', '前二型', '并', '发症'], [], ['前驱症状'], ['概', '念', '数数', '地数', '3', '件', '问“', '多', '少', '？”', '从', '头', '再数', '数数', '正确数', '次', '序', '后', '来', '5个', '大', '小', '次', '序', '4', '做5', '两数', '手', '指代', '表其', '中', '以另', '手', '指代', '表另', '所', '有', '很', '快', '1+', '2+2'], [], [], ['第四', '章'], ['皮疹型'], ['指', '标能'], ['地区骨', '髓库', '不', '必移', '除', '以', '内', '移植', '者'], ['一层', '向外', '不', '规则', '鼻腔', '黏膜'], ['突变细胞', '一般', '而言', '即', '可', '变态', '反应性', '缺陷', '病'], [], [], ['人平', '均', '正常', '游离酸', '低', '水平', '以', '后渐', '胃', '溃疡'], ['上到', '下', '从', '呼吸音', '稍粗', '呼吸音', '呼吸音', '啼', '哭时', '深吸', '气末', '肩胛间区'], ['禁', '忌证', '同', '胃镜', '证外', '上', '消化道', '发热者', '禁忌'], ['中要', '要给', '所教'], ['人来', '说', '例', '如', '或性'], ['含', '有', '总气量', 'VC+RV'], ['兼用', '型', '定压', '定压', '从', '而', '气道', '正压', '也', '还', '可', '以有', '起到', '也', '正压', '，', '，'], ['同', '一', '种', '同', '型', '其独', '特性', '有别', '于', '其他', '型', '杂交法', '链', '反应'], ['温', '抗体型', '行脾'], ['重', '建骨', '但', '是', '关节'], [], ['B因子', 'D因子', '种', '此类', '可', '见于', '多处血管', '外', '周动脉', 'T<sub>4<>', '转铁', '蛋白'], ['鼓', '励'], [], ['荧光法', '脱落细胞'], ['楊丙昂', '李军', '肾', '功能', '多', '普勒'], [], ['去甲肾上腺素'], [], [], ['症候', '群'], [], ['防治水', '电解质', '液要', '低血', '钾'], ['精神', '分裂症'], ['神经', '体液', '地予', '以'], ['胃', '隐窝', '处颈', '上皮细胞', '黏膜', '内', '容物'], [], ['吸收型'], ['普遍', '认为', '溶解学', '说', '肺', '气肿', 'α1', '-', 'AT', '死亡细菌', '蛋白', '溶解酶', 'α1', '-', 'AT', '缺乏者', '蛋白', '酶过', '多积', '聚', '肺', '组织', '蛋白', '肺', '气肿'], [], ['CD3<sup>+<>'], [], ['1', '3', '支气管', '镜', '后仰者'], ['到', '达', '在', '于', '最', '初', '异位', '肾', '从', '来'], ['可', '逆到', '肾上腺细胞'], ['连接部', '统计', '资料', '广泛', '应用', '围生期', '实际', '上UP', 'JO', '发育', '不良', '系', '供', '应', '肾', '下极', 'UP', 'JO', 'UP', 'JO', '男女', '左', '侧稍', 'UP', 'JO', '所', '比例', '其多', '有', 'UP', 'JO'], [], [], [], ['可测', '可测'], ['垂体', '激素', '氢化', '可', '的', '松', '2', '4', 'h', '促性', '腺激素', '需用性', '激素'], ['2倍'], ['极易', '胃食管', '应', '容物', '仰卧', '位见', '内', '方能', '时', '常', '下端数', '厘米', '黏膜面', '呈', '针尖', '状钡', '小结', '节影', '一', '半', '反流'], ['梁娟', '朱军', '1988', '.', '32', '4'], ['供氧', '循环', '系统'], [\"5'端\", '三', '核苷酸', '2', '中以', '最', 'CG', 'G拷', '贝数', '多', 'CG', 'G拷', '贝数'], [], ['精通业务', '之比', '科主任', '主治', '医', '师除', '较', '3年', '掌握心', '经皮', 'IC', 'U', 'IC', 'U', 'ICU护士', '之比', '为', '设', '有护', '士长', '一名', '多名', '不', '仅要', '仪上', '故', '障并', '监护', '电子工', '程师', '各', '种'], ['一分', '为', '丝点', '纵裂', '臂染', '色体', '丝粒', '不', '是', '而', '是', '条姊', '妹', '姊', '妹', '等', '臂染', '色体'], ['1', '1', '$$_', '_', 'CML细胞'], ['活', '检取', '小块', '线状荧光带'], [], ['一', '定量', '小标', '记物', '小钡', '条', '胶囊', '通过', '时间'], [], ['1', '3', '朱军', '图', '谱'], ['给', '氧', '法'], ['维生素', 'B', '面及', '有无', '维生素', 'B<sub>1<>', '胃肠道'], ['为', '了', '有', '创性'], [], ['低血糖会'], ['腰背酸痛', '少尿', '仔细核', '糖皮质激素', '对症'], ['7.许', '郑洁', 'vacA基因', '胃十二指肠', '杂志', ']'], [], [], ['有质'], ['虽为', '至', '少', '不', '是'], ['常', '常', '为', '什么？', '与果', '去动物', '园玩'], [], [], ['2', '5人', '1例', '上', '升到', '每8', '9人', '1例'], ['指非', '外伤性', '继发性', '脑出血', '因动脉瘤', '动静脉', '畸形', '致者', '以6', '年', '长儿'], [], ['常用', '于'], ['1', '4', '多', '棘慢', '波'], ['灶', '尤为', '多见', '早', '已', '并', '发脑', '头颅穿', '通伤', '因骨', '感染'], ['AIH', 'A分', '温', '抗体型', '冷抗体型', '抗', '体属', '为', '4℃', '不尽', '相同'], [], ['血友', '病甲', '输新', '鲜血', '患者', '血友', '病甲', '输新鲜', '每', '天', '血友', '病乙', '输等量', '血浆', '每', '天', '即', '可', '新鲜血', '中', '因子'], [], [], ['需', 'JIA少', '无', '相对', '应', '多侵犯', '膝', '最常', '关节'], ['尿常规', '血常规', '核左', '移常', '副伤寒', '见于', '粪常规', '蠕虫卵', '血生化', 'C反应', '有', '利于'], ['杨军', '启动子区', '4', '1'], ['为', '了', '应', '该', '当', '事', '假阳性率', '项新', '获知情'], [], ['鼠', '伤寒', '沙门菌', '肠炎'], ['普萘', '洛尔', '本病', '氧', '需量', '心绞', '痛心', '绞痛', '普萘', '洛尔', 'β受体阻', '滞剂', '品似'], ['马蹄', '肾没有', '马蹄', '外上', '行', '内下', '肾', '背侧', '后', '方'], ['这样就', '哪种'], ['总', '电位', '差称', '为', '无', '机硫', '一', '半', '细胞', '内液', '较', '为', '间有', '细胞', '内液', '其', '中', '阴离子'], [], [], [], ['可见', '其', '中', '胶质', '称星形细胞瘤', '3种', '非', '半透明', '肿瘤', '钙化', '其', '这', '错构瘤', '及', '可见', '视网膜色素', '缺失斑', '可见'], ['中磷酸吡哆醛', '维生素B<sub>6<>', '维生素B<sub>6<>', '维生素B<sub>6<>', '酶活性'], [], ['大成', '为', '一', '个', '成年', '人', '少男', '都要', '长时期', '就会', '大', '部分', '脂肪', '肝'], ['多见', '当断', '裂两端', '不张', 'CT', '扫描'], ['错义', '突变'], ['椭', '圆形', '红细胞', '增多症'], ['总未', '阴离子', '总未', '阳离子', '阳离子', '阴离子', '+UC=Cl<sup>-<>+'], ['未', '经', '地去偷', '别人'], ['肺容量'], ['再', '次'], ['不', '可用', '时要'], [], ['指', '导儿', '科用', '药理', '学涉', '及'], ['愈小', '愈差', '愈小', '贲门', '括约肌', '胃容量', '小肠', '结肠炎', '葡萄糖醛酸', '转移酶', '时', '间长'], ['马富西综合征'], ['经', '常'], ['萎靡', '不振'], ['小儿', '炎疑', '胰腺', '1', '个', '肝', '移植', '纤维囊性', '最', '好', '先做', '行ERCP', '高淀粉酶血症', '肠麻痹'], [], ['诺', '如', '病毒'], ['第十七章'], ['尿检查'], ['尿细菌学', '应列', '为'], ['黑便', '来', '自上', '黑便', '受血液', '鲜', '红色', '时', '间长', '黑便'], [], ['清除', '术用', '于', '肾限局性', '前用', '抗', '结核', '至', '少', '亦', '可', '做严', '重侧', '抗', '结核', '不', '得', '1.5年'], ['测', '温常', '无肛'], ['Vurea相比', '大分子', '除有', 'Vurea值', 'Ccr来', 'CAPD时', '60L', '9L', '6', '3L', '66L'], [], ['适应', '证为', '心脏', '病合', '并', '20ppm', '1ppm='], [], ['仅', '不', '抗', '0.5', '1g', '惊厥', '肺', '水肿', '抗', '癫痫'], [], ['原发', '孔型'], ['前进', '方向', '硬支', '气管', '镜', '无', '法', '到段', '由上', '而', '下', '有', '无', '有', '无'], [], ['神经根炎'], [], ['M<sup>2<>', '10月', '存活期'], [], [], ['查', '多克'], [], ['并集', '中于', '某一', '上', '课时', '虎头', '蛇尾', '强大动机', '感', '兴趣'], ['反义', '核苷酸'], ['很', '多', '相容性', '单卵', '双胎', '共患', '基因型', '对', '应'], ['根据Lawrence'], [], ['拍', '击声', '感为'], ['骨过度'], ['肺血管', '肺血管', '伴', '肺血管', '此病', '有', '动脉', '导管', '未', '单纯', '房间隔', '肺血管', '高血流量', '红细胞', '增多症', '收缩', '因子', '另一类', '肺血管', '血流', '血流'], [], [], ['入', '脑量', '比地西', '泮小', '尚', '未'], ['紫癜', '肾炎'], ['肾脏', '病为', '婴儿', '型'], ['病', '第5', '对', '一条', '大小', '不', '等', '5<sub>P<>', '1', '4', '～', '5<sub>P<>', '15', '第5', '号', '5<sub>P', '<', 'sub', '>', '-', '该', '易', '位型'], [], [], ['据Stakey', '该', '病多', '之比', '∶', '1', '此病', '高庆云', '1984年', '该'], ['即', '使', '直肠肛管'], ['肢', '带型'], ['右位心'], ['造影', '剂充', '盈', '蛇头', '样影', '内有'], ['红细胞', '凝血', '活酶'], ['携带', '者'], [], ['并', '发症', '肺血管', '动脉瘤', '大', '大', '一例', '堵塞术', '伞封', '堵术', '多', '普勒'], [], ['很', '多', 'CD4<sup>+<>', 'CD25<sup>+<>', 'T细胞', 'T细胞', 'IL-', '集落刺激', 'GM-CSF', '滑膜', '成纤维细胞', '软骨细胞', 'IL-6', 'IL-8', '呈正', '虹膜状体炎', '多', '关节型', '全身型', '极少'], ['本', '组'], [], ['尤以', '变慢', '不齐', '不清'], ['肺内', '低氧血症', '30%', '内动', '静脉', '100%', '不', '能', '静脉', '血时', '可', '吸纯', '氧', 'Qt='], [], [], [], [], [], ['肺毛细血管床', '少尿', '中枢', '神经系统'], ['说', '话清', '晰度', '发育史', '疾病史'], ['及踝', '前额头', '皮以', '及胸', '腰', '椎脊'], [], ['李铁', '一', '诊断', '学', '天津科学', '技术'], ['软', '确诊靠', '组织化学'], [], ['黄疸型', '而', '后', '肝性', '脑病', 'Ⅱ度', '凝血酶', '原活', '动度', '伴肝', '浊音', '界', '有', '时'], ['大细胞性'], [], ['可见', '“横', '结肠', '轮廓', '不清', '见胰'], ['GS', 'DⅢ', '葡萄糖苷酶', '肝', '肿大', '肌张力', '酮血症', '胰高血糖素', '尿儿', '茶', '酚胺'], [], ['新主动脉', '原肺动脉', '以了', '解其', '大动脉', '大动脉', '临床', '症状', '心肌', '灌注', '扫描', '心肌', '灌注', '不良', '大动脉', '转换', '术后'], ['视乳头', '水肿', '较', '长者'], ['中枢神经系统'], [], ['静止型'], [], ['基本', '上', '及', '其', '或', '者', '代谢', '物来', '如', '下'], ['成纤维细胞', '生长', '因子', '生长', '因子'], ['多见', '染色体', '显性'], ['-', '5'], ['很难'], [], [], ['肺动脉', '瓣'], ['肾积水', '比', '较', '不', '少人', '肾功能', '并', '发症', '另', '一', '方面', '泌尿', '外科', '肾积水', '比', '较重', '并', '未'], ['如骨', '吸入物', '并', '不能'], [], []]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZLhFhLledfiw","colab_type":"code","colab":{}},"source":["       # 对测试集进行测试\n","        logits, transition_params = sess.run([logits, transition_params], feed_dict={\n","            x: test_sen_index_list, y: test_labels,\n","            sequence_lengths: test_sen_len_list, keep_prob: 1.0\n","        })\n","        label_list = []\n","        for logit, seq_len in zip(logits, test_sen_len_list):\n","            # viterbi_decode通俗一点,作用就是返回最好的标签序列.这个函数只能够在测试时使用,在tensorflow外部解码\n","            # viterbi: 一个形状为[seq_len] 显示了最高分的标签索引的列表.\n","            # viterbi_score: 序列对应的概率值\n","            # 这是解码的过程，利用维比特算法结合概率转移矩阵求得最大的可能标注概率\n","            viterbi_seq, _ = viterbi_decode(logit[:seq_len], transition_params)\n","            label_list.append(viterbi_seq)\n","        # 索引向标签的转换\n","        label2tag = {}\n","        for label, tag in tag2label.items():\n","            label2tag[tag] = label\n","        tags_list = []\n","        for labels in label_list:\n","            tags = []\n","            for i in labels:\n","                tags.append(label2tag[i])\n","            tags_list.append(tags)\n","        # 计算精度\n","        accuracy_num = 0\n","        sum_num = 0\n","        for pre_tags, test_tags in zip(tags_list, test_tags_list):\n","            sum_num = sum_num + len(test_tags)\n","            for pre_tag, test_tag in zip(pre_tags, test_tags):\n","                if pre_tag == test_tag:\n","                    accuracy_num = accuracy_num + 1\n","        print(accuracy_num / sum_num)"],"execution_count":0,"outputs":[]}]}